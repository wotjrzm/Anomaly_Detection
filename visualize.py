import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.metrics import precision_recall_curve, confusion_matrix, auc
from tqdm import tqdm
from dataset import get_dataloaders
from model import TransformerVAE

# ==========================================
# 1. Configuration
# ==========================================
CONFIG = {
    'SEED': 42,
    'BATCH_SIZE': 256,
    'LATENT_DIM': 4,
    'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu'
}

def load_model_and_data():
    print(f"Loading Model & Data on {CONFIG['DEVICE']}...")
    _, test_loader, input_dim = get_dataloaders(CONFIG)
    
    model = TransformerVAE(input_dim=input_dim, latent_dim=CONFIG['LATENT_DIM']).to(CONFIG['DEVICE'])
    try:
        model.load_state_dict(torch.load("best_model.pth", map_location=CONFIG['DEVICE']))
        print("'best_model.pth' ë¡œë“œ ì„±ê³µ!")
    except Exception as e:
        print(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        exit()
        
    model.eval()
    return model, test_loader

def get_mahalanobis_params(model, dataloader, device):
    """
    ì •ìƒ ë°ì´í„°ì˜ ë¶„í¬(í‰ê· , ê³µë¶„ì‚° ì—­í–‰ë ¬)ë¥¼ ë¯¸ë¦¬ ê³„ì‚°
    """
    print("1. ì •ìƒ ë°ì´í„° ë¶„í¬ í•™ìŠµ ì¤‘...")
    z_normals = []
    with torch.no_grad():
        for x, y in dataloader:
            x = x.to(device)
            # ì •ìƒ(0) ë°ì´í„°ë§Œ ì¶”ì¶œ
            if (y == 0).sum() > 0:
                mu, _ = model.encode(x[y==0])
                z_normals.append(mu.cpu().numpy())
    
    z_normals = np.concatenate(z_normals)
    
    # í‰ê· ê³¼ ê³µë¶„ì‚° ê³„ì‚°
    mean = np.mean(z_normals, axis=0)
    cov = np.cov(z_normals, rowvar=False)
    # ì—­í–‰ë ¬ ê³„ì‚° (íŠ¹ì´í–‰ë ¬ ë°©ì§€ìš© pinv ì‚¬ìš©)
    inv_cov = np.linalg.pinv(cov)
    
    return mean, inv_cov

def get_hybrid_scores(model, dataloader, device, mean, inv_cov):
    """
    Recon Error + Mahalanobis Distance ê³„ì‚°
    """
    print("2. ì „ì²´ ë°ì´í„° ìŠ¤ì½”ì–´ë§ (Mahalanobis ì ìš©)...")
    all_scores = []
    all_labels = []
    
    with torch.no_grad():
        for x, y in dataloader:
            x = x.to(device)
            
            # 1) ì¬êµ¬ì¶• ì˜¤ì°¨ (Reconstruction Error)
            recon_x, mu, _, _ = model(x)
            recon_loss = torch.mean(torch.abs(x - recon_x), dim=1).cpu().numpy()
            
            # 2) ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ (Mahalanobis Distance)
            # (x - mu)^T * Sigma^-1 * (x - mu)
            z_numpy = mu.cpu().numpy()
            diff = z_numpy - mean
            # Vectorized implementation for batch processing
            # (Batch, Dim) @ (Dim, Dim) -> (Batch, Dim)
            left = np.dot(diff, inv_cov) 
            # Row-wise dot product
            mahal_dist = np.sqrt(np.sum(left * diff, axis=1))
            
            # 3) ìµœì¢… ì ìˆ˜ (ë‹¨ìˆœ í•©ì‚° í˜¹ì€ ê°€ì¤‘ì¹˜ ì ìš© ê°€ëŠ¥)
            final_score = recon_loss + mahal_dist
            
            all_scores.extend(final_score)
            all_labels.extend(y.cpu().numpy())
            
    return np.array(all_scores), np.array(all_labels)

# ==========================================
# ì‹œê°í™” í•¨ìˆ˜ë“¤ (ì¶”ê°€ëœ PR Curve, Confusion Matrix)
# ==========================================

def plot_performance_metrics(scores, labels):
    """
    ì„±ê³¼ ì…ì¦ìš© í•µì‹¬ ê·¸ë˜í”„ 3ì¢… ì„¸íŠ¸
    """
    print("\n[Vis] ì„±ê³¼ ë¶„ì„ ê·¸ë˜í”„ ìƒì„± ì¤‘...")
    plt.figure(figsize=(18, 5))
    
    # --- 1. Score Distribution (Separability) ---
    plt.subplot(1, 3, 1)
    sns.histplot(x=scores, hue=labels, kde=True, bins=50, 
                 palette={0: 'blue', 1: 'red'}, common_norm=False, stat='density')
    plt.title('Anomaly Score Distribution', fontsize=14)
    plt.xlabel('Hybrid Score (Recon + Mahalanobis)')
    plt.legend(title='Label', labels=['Fraud', 'Normal'])
    plt.grid(alpha=0.3)

    # --- 2. PR Curve & Best F1 ---
    precision, recall, thresholds = precision_recall_curve(labels, scores)
    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)
    best_idx = np.argmax(f1_scores)
    best_thresh = thresholds[best_idx]
    pr_auc = auc(recall, precision)
    
    plt.subplot(1, 3, 2)
    plt.plot(recall, precision, marker='.', label=f'AUPRC = {pr_auc:.4f}', color='darkorange')
    plt.scatter(recall[best_idx], precision[best_idx], marker='o', c='black', s=100, label=f'Best F1 ({f1_scores[best_idx]:.4f})', zorder=10)
    plt.title('Precision-Recall Curve', fontsize=14)
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.legend()
    plt.grid(alpha=0.3)

    # --- 3. Confusion Matrix (at Best F1) ---
    plt.subplot(1, 3, 3)
    preds = (scores >= best_thresh).astype(int)
    cm = confusion_matrix(labels, preds)
    
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={"size": 14})
    plt.title(f'Confusion Matrix (Thresh={best_thresh:.3f})', fontsize=14)
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.xticks([0.5, 1.5], ['Normal', 'Fraud'])
    plt.yticks([0.5, 1.5], ['Normal', 'Fraud'])

    plt.tight_layout()
    plt.savefig("vis_performance_metrics.png")
    print("âœ… ì €ì¥ ì™„ë£Œ: vis_performance_metrics.png")

# ==========================================
# Main Execution
# ==========================================
if __name__ == "__main__":
    # 1. ëª¨ë¸ ë¡œë“œ
    model, test_loader = load_model_and_data()
    
    # 2. ì •ìƒ ë°ì´í„° ë¶„í¬(Mean, Cov) ê³„ì‚°
    mean, inv_cov = get_mahalanobis_params(model, test_loader, CONFIG['DEVICE'])
    
    # 3. Mahalanobis ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°
    scores, labels = get_hybrid_scores(model, test_loader, CONFIG['DEVICE'], mean, inv_cov)
    
    # 4. í•µì‹¬ ê·¸ë˜í”„ 3ì¢… ê·¸ë¦¬ê¸° (ë¶„í¬, PR Curve, í˜¼ë™í–‰ë ¬)
    plot_performance_metrics(scores, labels)
    
    print("\nğŸ‰ ë¶„ì„ ì™„ë£Œ! 'vis_performance_metrics.png' íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")