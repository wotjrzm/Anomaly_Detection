import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from tqdm import tqdm
from dataset import get_dataloaders
from model import TransformerVAE

# ==========================================
# 1. Configuration
# ==========================================
CONFIG = {
    'SEED': 42,
    'BATCH_SIZE': 256,
    'LATENT_DIM': 4,
    'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu'
}

def load_model_and_data():
    print(f"Loading Model & Data on {CONFIG['DEVICE']}...")
    _, test_loader, input_dim = get_dataloaders(CONFIG)
    
    # ëª¨ë¸ ë¡œë“œ
    model = TransformerVAE(input_dim=input_dim, latent_dim=CONFIG['LATENT_DIM']).to(CONFIG['DEVICE'])
    try:
        model.load_state_dict(torch.load("best_model.pth", map_location=CONFIG['DEVICE']))
        print("'best_model.pth' ë¡œë“œ ì„±ê³µ!")
    except Exception as e:
        print(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        exit()
        
    model.eval()
    return model, test_loader

def get_hybrid_scores(model, dataloader, device):
    """
    ëª¨ë“  í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ Hybrid Score (Recon + Latent Distance) ê³„ì‚°
    """
    print("\n[Computing Scores] ì ìˆ˜ ë¶„í¬ ê³„ì‚° ì¤‘...")
    
    # 1. ì •ìƒ ë°ì´í„°ì˜ ì¤‘ì‹¬ì (Center) ê³„ì‚° (Test ì…‹ ë‚´ì˜ ì •ìƒ ë°ì´í„° ì´ìš©)
    # (ì›ì¹™ì€ Train ì…‹ìœ¼ë¡œ í•´ì•¼ í•˜ì§€ë§Œ í¸ì˜ìƒ Test ì…‹ì˜ ì •ìƒ ë°ì´í„°ë¡œ ê·¼ì‚¬)
    z_normals = []
    with torch.no_grad():
        for x, y in dataloader:
            x = x.to(device)
            if (y == 0).sum() > 0:
                mu, _ = model.encode(x[y==0])
                z_normals.append(mu)
    normal_center = torch.cat(z_normals).mean(dim=0)
    
    # 2. ì „ì²´ ë°ì´í„° ìŠ¤ì½”ì–´ë§
    all_scores = []
    all_labels = []
    
    with torch.no_grad():
        for x, y in dataloader:
            x = x.to(device)
            
            # ë³µì› ì˜¤ì°¨ (L1)
            recon_x, mu, _, _ = model(x)
            recon_loss = torch.mean(torch.abs(x - recon_x), dim=1)
            
            # ì ì¬ ê±°ë¦¬ (Euclidean)
            latent_dist = torch.norm(mu - normal_center, p=2, dim=1)
            
            # ìµœì¢… ì ìˆ˜ í•©ì‚°
            final_score = recon_loss + latent_dist
            
            all_scores.extend(final_score.cpu().numpy())
            all_labels.extend(y.cpu().numpy())
            
    return np.array(all_scores), np.array(all_labels)

# ==========================================
# ì‹œê°í™” í•¨ìˆ˜ë“¤
# ==========================================

def plot_score_histogram(scores, labels):
    """
    [í•µì‹¬] ì •ìƒê³¼ ì‚¬ê¸°ì˜ ì ìˆ˜ ë¶„í¬ ì°¨ì´ë¥¼ ë³´ì—¬ì£¼ëŠ” íˆìŠ¤í† ê·¸ë¨
    """
    print("\n[Vis 1] Score Histogram ê·¸ë¦¬ëŠ” ì¤‘...")
    
    plt.figure(figsize=(10, 6))
    
    # ì •ìƒ(Normal) - íŒŒë€ìƒ‰
    sns.histplot(scores[labels==0], color='dodgerblue', label='Normal', 
                 kde=True, stat="density", bins=50, alpha=0.3)
    
    # ì‚¬ê¸°(Fraud) - ë¹¨ê°„ìƒ‰
    sns.histplot(scores[labels==1], color='red', label='Fraud', 
                 kde=True, stat="density", bins=50, alpha=0.3)
    
    plt.title("Anomaly Score Distribution (The Proof of Separation)", fontsize=15)
    plt.xlabel("Hybrid Anomaly Score (Lower is Normal)")
    plt.ylabel("Density")
    plt.legend()
    plt.grid(True, alpha=0.2)
    
    # ë¡œê·¸ ìŠ¤ì¼€ì¼ (ì ìˆ˜ ì°¨ì´ê°€ ë„ˆë¬´ í´ ê²½ìš°ë¥¼ ëŒ€ë¹„)
    plt.xscale('log')
    plt.xlabel("Hybrid Anomaly Score (Log Scale)")
    
    save_path = "vis_histogram.png"
    plt.savefig(save_path)
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {save_path}")

def plot_error_heatmap(model, dataloader, device):
    """
    [ìƒì„¸ ë¶„ì„] ì‚¬ê¸° ë°ì´í„°ê°€ 'ì–´ë””ê°€' í‹€ë ¸ëŠ”ì§€ ë³´ì—¬ì£¼ëŠ” íˆíŠ¸ë§µ
    """
    print("\n[Vis 2] Error Heatmap ê·¸ë¦¬ëŠ” ì¤‘...")
    
    # ì‚¬ê¸° ë°ì´í„° 5ê°œ, ì •ìƒ ë°ì´í„° 1ê°œ ìƒ˜í”Œë§
    fraud_samples = []
    normal_sample = None
    
    with torch.no_grad():
        for x, y in dataloader:
            if len(fraud_samples) < 5 and (y == 1).sum() > 0:
                fraud_samples.append(x[y==1][0])
            if normal_sample is None and (y == 0).sum() > 0:
                normal_sample = x[y==0][0]
            
            if len(fraud_samples) >= 5 and normal_sample is not None:
                break
    
    # í•˜ë‚˜ë¡œ í•©ì¹˜ê¸° (ë§¨ ìœ„: ì •ìƒ, ì•„ë˜ 5ê°œ: ì‚¬ê¸°)
    samples = torch.stack([normal_sample] + fraud_samples).to(device)
    
    # ëª¨ë¸ í†µê³¼
    with torch.no_grad():
        recon, _, _, _ = model(samples)
        
    # ì ˆëŒ€ ì˜¤ì°¨ ê³„ì‚° (Absolute Error)
    # (N, 29)
    errors = torch.abs(samples - recon).cpu().numpy()
    
    plt.figure(figsize=(12, 6))
    yticklabels = ['Normal'] + [f'Fraud {i+1}' for i in range(5)]
    
    # Heatmap ê·¸ë¦¬ê¸°
    sns.heatmap(errors, cmap='Reds', yticklabels=yticklabels, cbar_kws={'label': 'Reconstruction Error'})
    
    plt.title("Feature-wise Reconstruction Error Heatmap", fontsize=15)
    plt.xlabel("Feature Index (V1 ~ V29)")
    plt.tight_layout()
    
    save_path = "vis_heatmap.png"
    plt.savefig(save_path)
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {save_path}")

def plot_tsne(model, dataloader, device):
    """
    [ê³µê°„ ë¶„ì„] Latent Space t-SNE
    """
    print("\n[Vis 3] t-SNE ê³„ì‚° ì¤‘... (ë°ì´í„° 2000ê°œ ìƒ˜í”Œë§)")
    
    z_list = []
    y_list = []
    max_samples = 2000
    
    with torch.no_grad():
        for x, y in dataloader:
            x = x.to(device)
            mu, _ = model.encode(x)
            z_list.append(mu.cpu().numpy())
            y_list.append(y.cpu().numpy())
            if len(np.concatenate(y_list)) > max_samples:
                break
                
    z = np.concatenate(z_list)[:max_samples]
    labels = np.concatenate(y_list)[:max_samples]
    
    # [ìˆ˜ì •] n_iter=1000 ì‚­ì œ (ê¸°ë³¸ê°’ ì‚¬ìš©)
    # ì—ëŸ¬ ì›ì¸: ì¼ë¶€ scikit-learn ë²„ì „ì—ì„œ n_iter íŒŒë¼ë¯¸í„° ì¶©ëŒ ë°œìƒ
    tsne = TSNE(n_components=2, perplexity=30, random_state=42)
    
    z_2d = tsne.fit_transform(z)
    
    plt.figure(figsize=(10, 8))
    
    # ì •ìƒ ë¨¼ì € ê·¸ë¦¬ê¸° (ë’¤ì— ê¹”ë¦¬ê²Œ)
    plt.scatter(z_2d[labels==0, 0], z_2d[labels==0, 1], 
                c='lightgray', label='Normal', s=10, alpha=0.5)
    
    # ì‚¬ê¸° ë‚˜ì¤‘ì— ê·¸ë¦¬ê¸° (ìœ„ì— ëœ¨ê²Œ)
    plt.scatter(z_2d[labels==1, 0], z_2d[labels==1, 1], 
                c='red', label='Fraud', s=30, alpha=0.9, marker='x')
    
    plt.title("Latent Space Distribution (t-SNE)", fontsize=15)
    plt.legend()
    plt.grid(True, alpha=0.2)
    
    save_path = "vis_tsne.png"
    plt.savefig(save_path)
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {save_path}")

# ==========================================
# Main Execution
# ==========================================
if __name__ == "__main__":
    # 1. ì¤€ë¹„
    model, test_loader = load_model_and_data()
    
    # 2. ì ìˆ˜ ê³„ì‚° (Hybrid Score)
    scores, labels = get_hybrid_scores(model, test_loader, CONFIG['DEVICE'])
    
    # 3. ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
    plot_score_histogram(scores, labels) # ë¶„í¬ í™•ì¸ (ê°€ì¥ ì¤‘ìš”)
    plot_error_heatmap(model, test_loader, CONFIG['DEVICE']) # íŠ¹ì§•ë³„ ì—ëŸ¬ í™•ì¸
    plot_tsne(model, test_loader, CONFIG['DEVICE']) # ê³µê°„ ë¶„ë¦¬ í™•ì¸
    
    print("\nğŸ‰ ëª¨ë“  ì‹œê°í™” ì™„ë£Œ! ìƒì„±ëœ 3ê°œì˜ png íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")