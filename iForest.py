import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve
from dataset import get_dataloaders

# ==========================================
# 1. ì„¤ì •
# ==========================================
CONFIG = {
    'BATCH_SIZE': 2048, 
    'DEVICE': 'cpu',
    'SEED': 42 
}

def run_baseline():
    print("ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì¤‘...")
    
    _, test_loader, _ = get_dataloaders(CONFIG)
    
    X_test = []
    y_test = []
    
    for x, y in test_loader:
        X_test.append(x.numpy())
        y_test.append(y.numpy())
        
    X_test = np.concatenate(X_test)
    y_test = np.concatenate(y_test)
    
    print(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {X_test.shape}")

    # ==========================================
    # 2. Isolation Forest í•™ìŠµ ë° ì˜ˆì¸¡
    # ==========================================
    print("ğŸŒ² Isolation Forest í•™ìŠµ ì¤‘... (Baseline)")
    
    # contamination: ì‚¬ê¸° ë°ì´í„° ë¹„ìœ¨ (ì•½ 0.0017)
    iso_forest = IsolationForest(
        n_estimators=100, 
        contamination=0.0017, 
        random_state=42, 
        n_jobs=-1
    )
    
    iso_forest.fit(X_test) 
    
    scores = -iso_forest.score_samples(X_test)

    # ==========================================
    # 3. ì„±ëŠ¥ í‰ê°€ (AUROC, AUPRC, F1)
    # ==========================================
    auroc = roc_auc_score(y_test, scores)
    auprc = average_precision_score(y_test, scores)
    
    precisions, recalls, thresholds = precision_recall_curve(y_test, scores)
    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)
    best_f1 = np.max(f1_scores)

    print("\n" + "="*40)
    print(f"ğŸ“Š [Baseline Result: Isolation Forest]")
    print(f" - AUROC : {auroc:.4f}")
    print(f" - AUPRC : {auprc:.4f}")
    print(f" - Best F1 : {best_f1:.4f}")
    print("="*40)

if __name__ == "__main__":
    run_baseline()